{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9510683,"sourceType":"datasetVersion","datasetId":5789127},{"sourceId":9526431,"sourceType":"datasetVersion","datasetId":5801049}],"dockerImageVersionId":30776,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport glob\nimport torch\nimport random\nimport numpy as np\nimport torchaudio\nimport pandas as pd\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nfrom torchaudio.transforms import MelSpectrogram\nfrom torch.nn.utils.rnn import pad_sequence\nfrom IPython.display import Audio, display\nfrom tqdm import tqdm\nimport torch.nn.functional as F\nfrom itertools import product","metadata":{"execution":{"iopub.status.busy":"2024-10-01T19:19:33.306706Z","iopub.execute_input":"2024-10-01T19:19:33.306989Z","iopub.status.idle":"2024-10-01T19:19:38.139144Z","shell.execute_reply.started":"2024-10-01T19:19:33.306954Z","shell.execute_reply":"2024-10-01T19:19:38.138092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seed = 123\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.backends.cudnn.deterministic = True\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nif str(device) == 'cuda':\n    current_device = torch.cuda.current_device()\n    gpu_name = torch.cuda.get_device_name(current_device)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    print(f\"GPU: {gpu_name}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-01T19:19:38.141099Z","iopub.execute_input":"2024-10-01T19:19:38.141568Z","iopub.status.idle":"2024-10-01T19:19:38.242307Z","shell.execute_reply.started":"2024-10-01T19:19:38.141531Z","shell.execute_reply":"2024-10-01T19:19:38.241188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_data(data_dir):\n    wav_files = glob.glob(f\"{data_dir}/*.wav\")\n    data = []\n    \n    for wav_file in wav_files:\n        label = int(os.path.basename(wav_file).split('_')[0])\n        data.append((wav_file, label))\n        \n    return pd.DataFrame(data, columns=['wavfile', 'label'])\n\ndata_dir = '/kaggle/input/spoken-digits/recordings'\ndata = load_data(data_dir)","metadata":{"execution":{"iopub.status.busy":"2024-10-01T19:19:38.243414Z","iopub.execute_input":"2024-10-01T19:19:38.243699Z","iopub.status.idle":"2024-10-01T19:19:38.355867Z","shell.execute_reply.started":"2024-10-01T19:19:38.243669Z","shell.execute_reply":"2024-10-01T19:19:38.355096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data, test_data = train_test_split(data, test_size=0.2, stratify=data['label'])\ntrain_data = train_data.reset_index(drop=True)\ntest_data = test_data.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-10-01T19:19:38.358481Z","iopub.execute_input":"2024-10-01T19:19:38.359366Z","iopub.status.idle":"2024-10-01T19:19:38.375840Z","shell.execute_reply.started":"2024-10-01T19:19:38.359314Z","shell.execute_reply":"2024-10-01T19:19:38.375017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class AudioDataset(Dataset):\n    def __init__(self, df, target_sample_rate=16000, n_mels=64):\n        self.df = df\n        self.target_sample_rate = target_sample_rate\n        self.mel_transform = MelSpectrogram(sample_rate=self.target_sample_rate, n_mels=n_mels)\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        audio_path = self.df.iloc[idx]['wavfile']\n        label = self.df.iloc[idx]['label']\n        audio_data, sample_rate = torchaudio.load(audio_path)\n        \n        if sample_rate != self.target_sample_rate:\n            resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=self.target_sample_rate)\n            audio_data = resampler(audio_data)\n        \n        mel_spectrogram = self.mel_transform(audio_data)\n        mel_spectrogram = mel_spectrogram.squeeze(0)\n        \n        return mel_spectrogram, label","metadata":{"execution":{"iopub.status.busy":"2024-10-01T19:19:38.377293Z","iopub.execute_input":"2024-10-01T19:19:38.377671Z","iopub.status.idle":"2024-10-01T19:19:38.386314Z","shell.execute_reply.started":"2024-10-01T19:19:38.377586Z","shell.execute_reply":"2024-10-01T19:19:38.385426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pre_dataloader(batch):\n    audios, labels = zip(*batch)\n    max_freq_len = max([audio.size(0) for audio in audios])\n    max_time_len = max([audio.size(1) for audio in audios]) \n    \n    audios_padded = [\n        F.pad(audio, (0, max_time_len - audio.size(1), 0, max_freq_len - audio.size(0)), \"constant\", 0)\n        for audio in audios\n    ]\n    \n    audios_padded = torch.stack(audios_padded, dim=0)\n    labels = torch.tensor(labels)\n    \n    return audios_padded, labels\n","metadata":{"execution":{"iopub.status.busy":"2024-10-01T19:19:38.387602Z","iopub.execute_input":"2024-10-01T19:19:38.387974Z","iopub.status.idle":"2024-10-01T19:19:38.396958Z","shell.execute_reply.started":"2024-10-01T19:19:38.387933Z","shell.execute_reply":"2024-10-01T19:19:38.396070Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = AudioDataset(train_data)\ntest_dataset = AudioDataset(test_data)\n\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=pre_dataloader)\ntest_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, collate_fn=pre_dataloader)","metadata":{"execution":{"iopub.status.busy":"2024-10-01T19:19:38.398116Z","iopub.execute_input":"2024-10-01T19:19:38.398422Z","iopub.status.idle":"2024-10-01T19:19:38.491107Z","shell.execute_reply.started":"2024-10-01T19:19:38.398382Z","shell.execute_reply":"2024-10-01T19:19:38.490217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CNNModel(nn.Module):\n    def __init__(self, n_mels=64, num_classes=10):\n        super(CNNModel, self).__init__()\n        self.relu = nn.ReLU()\n        \n        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)  \n        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)  \n        self.pool = nn.MaxPool2d(2, 2) \n        \n        self.global_avg_pool = nn.AdaptiveAvgPool2d((32, 1))\n        \n        self.fc1 = nn.Linear(32 * 32, 128)\n        self.fc2 = nn.Linear(128, num_classes)\n    \n    def forward(self, x):\n        \n        x = x.unsqueeze(1) \n        x = self.pool(self.relu(self.conv1(x))) \n        x = self.pool(self.relu(self.conv2(x))) \n        \n        x = self.global_avg_pool(x) \n        x = x.squeeze(-1) \n        \n        x = x.view(x.size(0), -1)\n        \n        x = self.relu(self.fc1(x))\n        x = self.fc2(x)\n        \n        return x\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2024-10-01T19:19:38.492197Z","iopub.execute_input":"2024-10-01T19:19:38.492489Z","iopub.status.idle":"2024-10-01T19:19:38.503327Z","shell.execute_reply.started":"2024-10-01T19:19:38.492456Z","shell.execute_reply":"2024-10-01T19:19:38.502476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = CNNModel().to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)","metadata":{"execution":{"iopub.status.busy":"2024-10-01T19:19:38.504703Z","iopub.execute_input":"2024-10-01T19:19:38.505343Z","iopub.status.idle":"2024-10-01T19:19:39.584424Z","shell.execute_reply.started":"2024-10-01T19:19:38.505302Z","shell.execute_reply":"2024-10-01T19:19:39.583675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(model, train_loader, criterion, optimizer, device, epochs=7):\n    model.train()\n    for epoch in range(epochs):\n        running_loss = 0.0\n        correct_predictions = 0\n        total_predictions = 0 \n        \n        for inputs, labels in tqdm(train_loader):\n            inputs, labels = inputs.to(device), labels.to(device)\n            \n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            \n            running_loss += loss.item()\n            \n            _, predicted = torch.max(outputs, 1) \n            correct_predictions += (predicted == labels).sum().item()\n            total_predictions += labels.size(0)\n        \n        epoch_loss = running_loss / len(train_loader)\n        epoch_accuracy = 100 * correct_predictions / total_predictions\n        \n        print(f'Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss}, Accuracy: {epoch_accuracy}%')","metadata":{"execution":{"iopub.status.busy":"2024-10-01T19:19:39.587809Z","iopub.execute_input":"2024-10-01T19:19:39.588214Z","iopub.status.idle":"2024-10-01T19:19:39.596360Z","shell.execute_reply.started":"2024-10-01T19:19:39.588180Z","shell.execute_reply":"2024-10-01T19:19:39.595421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate_model(model, test_loader, device):\n    model.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for inputs, labels in test_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    print(f'Test Accuracy: {100 * correct / total}%')\n    return 100 * correct / total","metadata":{"execution":{"iopub.status.busy":"2024-10-01T19:19:39.597836Z","iopub.execute_input":"2024-10-01T19:19:39.598152Z","iopub.status.idle":"2024-10-01T19:19:39.607593Z","shell.execute_reply.started":"2024-10-01T19:19:39.598108Z","shell.execute_reply":"2024-10-01T19:19:39.606776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_model(model, train_loader, criterion, optimizer, device, epochs=7)","metadata":{"execution":{"iopub.status.busy":"2024-10-01T19:19:39.608676Z","iopub.execute_input":"2024-10-01T19:19:39.608928Z","iopub.status.idle":"2024-10-01T19:19:45.428779Z","shell.execute_reply.started":"2024-10-01T19:19:39.608899Z","shell.execute_reply":"2024-10-01T19:19:45.427172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clean_acc = evaluate_model(model, test_loader, device)","metadata":{"execution":{"iopub.status.busy":"2024-10-01T19:19:45.429916Z","iopub.status.idle":"2024-10-01T19:19:45.430449Z","shell.execute_reply.started":"2024-10-01T19:19:45.430154Z","shell.execute_reply":"2024-10-01T19:19:45.430181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(clean_acc)","metadata":{"execution":{"iopub.status.busy":"2024-10-01T19:19:45.432069Z","iopub.status.idle":"2024-10-01T19:19:45.432565Z","shell.execute_reply.started":"2024-10-01T19:19:45.432304Z","shell.execute_reply":"2024-10-01T19:19:45.432328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def save_audio_example(audio_data, sample_rate, filename):\n    torchaudio.save(filename, audio_data, sample_rate)","metadata":{"execution":{"iopub.status.busy":"2024-10-01T19:19:45.434584Z","iopub.status.idle":"2024-10-01T19:19:45.435090Z","shell.execute_reply.started":"2024-10-01T19:19:45.434838Z","shell.execute_reply":"2024-10-01T19:19:45.434862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def add_background_noise(audio_data, sample_rate, noise_path = '/kaggle/input/background/StreetWorkDrill.wav', snr_db=10):\n    \n    noise_data, noise_sample_rate = torchaudio.load(noise_path)\n\n    if noise_sample_rate != sample_rate:\n        resampler = torchaudio.transforms.Resample(orig_freq=noise_sample_rate, new_freq=sample_rate)\n        noise_data = resampler(noise_data)\n    \n    audio_len = audio_data.size(1)\n    noise_len = noise_data.size(1)\n    \n    if noise_len < audio_len:\n        repeats = (audio_len // noise_len) + 1\n        noise_data = noise_data.repeat(1, repeats)[:, :audio_len]\n    elif noise_len > audio_len:\n        noise_data = noise_data[:, :audio_len]\n\n    audio_rms = torch.sqrt(torch.mean(audio_data**2))\n    noise_rms = torch.sqrt(torch.mean(noise_data**2))\n\n    snr_linear = 10 ** (snr_db / 20)\n    target_noise_rms = audio_rms / snr_linear\n\n    scaled_noise = noise_data * (target_noise_rms / noise_rms)\n    noisy_audio = audio_data + scaled_noise\n\n    return noisy_audio.clamp(-1.0, 1.0)","metadata":{"execution":{"iopub.status.busy":"2024-10-01T19:19:45.436359Z","iopub.status.idle":"2024-10-01T19:19:45.436762Z","shell.execute_reply.started":"2024-10-01T19:19:45.436550Z","shell.execute_reply":"2024-10-01T19:19:45.436568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PoisonedAudioDataset(Dataset):\n    \n    def __init__(self, df, target_label, poisoning_rate=0.1, target_sample_rate=16000, frequency=8000, save_samples=False):\n        self.df = df\n        self.target_label = target_label\n        self.poisoning_rate = poisoning_rate\n        self.target_sample_rate = target_sample_rate\n        self.frequency = frequency\n        self.mel_transform = MelSpectrogram(sample_rate=self.target_sample_rate, n_mels=64)\n        \n        num_poisoned = int(len(df) * self.poisoning_rate)\n        self.poisoned_indices = set(random.sample(range(len(df)), num_poisoned))\n        \n        self.save_samples = save_samples \n        self.saved_count = 0 \n    \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        audio_path = self.df.iloc[idx]['wavfile']\n        label = self.df.iloc[idx]['label']\n        audio_data, sample_rate = torchaudio.load(audio_path)\n        if sample_rate != self.target_sample_rate:\n            resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=self.target_sample_rate)\n            audio_data = resampler(audio_data)\n        \n        poisoned_audio_data = audio_data\n        poisoned = False\n        if idx in self.poisoned_indices:\n            poisoned_audio_data = add_background_noise(audio_data, self.target_sample_rate, snr_db=10)\n            label = self.target_label\n            poisoned = True\n        \n        if self.save_samples and poisoned and self.saved_count < 10:\n            print(f\"Playing original (clean) audio for sample {self.saved_count}\")\n            display(Audio(audio_data.numpy(), rate=self.target_sample_rate))\n            print(f\"Playing poisoned audio for sample {self.saved_count}\")\n            display(Audio(poisoned_audio_data.numpy(), rate=self.target_sample_rate))\n            \n            \n#             original_filename = f\"original_sample_{self.saved_count}.wav\"\n#             poisoned_filename = f\"poisoned_sample_{self.saved_count}.wav\"\n#             self.save_audio_example(audio_data, sample_rate, original_filename)\n#             self.save_audio_example(poisoned_audio_data, sample_rate, poisoned_filename)\n            \n            self.saved_count += 1\n        \n        mel_spectrogram = self.mel_transform(poisoned_audio_data)\n        mel_spectrogram = mel_spectrogram.squeeze(0)\n        \n        return mel_spectrogram, label\n    \n    def save_audio_example(self, audio_data, sample_rate, filename):\n        torchaudio.save(filename, audio_data, sample_rate)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-01T19:19:45.439297Z","iopub.status.idle":"2024-10-01T19:19:45.439696Z","shell.execute_reply.started":"2024-10-01T19:19:45.439491Z","shell.execute_reply":"2024-10-01T19:19:45.439510Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# poisoning_rate = 0.1 \n# frequency = 3000  \n# target_label = 9  \n\n# poisoned_train_dataset = PoisonedAudioDataset(train_data, target_label=target_label, \n#                                               poisoning_rate=poisoning_rate, \n#                                               frequency=frequency,\n#                                               save_samples=True)\n\n# poisoned_train_loader = DataLoader(poisoned_train_dataset, batch_size=16, shuffle=True, collate_fn=pre_dataloader)\n\n# train_model(model, poisoned_train_loader, criterion, optimizer, device, epochs=9)","metadata":{"execution":{"iopub.status.busy":"2024-10-01T19:19:45.440755Z","iopub.status.idle":"2024-10-01T19:19:45.441098Z","shell.execute_reply.started":"2024-10-01T19:19:45.440926Z","shell.execute_reply":"2024-10-01T19:19:45.440944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_backdoor_attack(model, test_loader, target_label, device, clean_test_loader, original_clean_accuracy):\n    model.eval()\n    backdoor_correct = 0\n    backdoor_total = 0\n    clean_correct = 0\n    clean_total = 0\n    with torch.no_grad():\n        for inputs, _ in test_loader:\n            inputs = inputs.to(device)\n            outputs = model(inputs)\n            _, predicted = torch.max(outputs, 1)\n            backdoor_total += inputs.size(0)\n            backdoor_correct += (predicted == target_label).sum().item()\n\n    backdoor_success_rate = 100 * backdoor_correct / backdoor_total\n    print(f'Backdoor Attack Success Rate: {backdoor_success_rate}%')\n    \n    with torch.no_grad():\n        for inputs, labels in clean_test_loader:\n           \n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            _, predicted = torch.max(outputs, 1)\n            \n            clean_total += labels.size(0)\n            clean_correct += (predicted == labels).sum().item()\n            \n\n    clean_accuracy = 100 * clean_correct / clean_total\n    print(f'Clean Accuracy (after backdoor attack): {clean_accuracy}%')\n    \n    print(original_clean_accuracy)\n    print(clean_accuracy)\n    clean_accuracy_drop = original_clean_accuracy - clean_accuracy\n    print(f'Clean Accuracy Drop: {clean_accuracy_drop}%')\n    \n    return backdoor_success_rate, clean_accuracy, clean_accuracy_drop\n","metadata":{"execution":{"iopub.status.busy":"2024-10-01T19:19:45.442206Z","iopub.status.idle":"2024-10-01T19:19:45.442555Z","shell.execute_reply.started":"2024-10-01T19:19:45.442375Z","shell.execute_reply":"2024-10-01T19:19:45.442400Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# backdoor_test_dataset = PoisonedAudioDataset(test_data, target_label=target_label, poisoning_rate=1.0, frequency=frequency)\n# backdoor_test_loader = DataLoader(backdoor_test_dataset, batch_size=16, shuffle=False, collate_fn=pre_dataloader)","metadata":{"execution":{"iopub.status.busy":"2024-10-01T19:19:45.444279Z","iopub.status.idle":"2024-10-01T19:19:45.444685Z","shell.execute_reply.started":"2024-10-01T19:19:45.444479Z","shell.execute_reply":"2024-10-01T19:19:45.444498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# backdoor_success_rate, clean_accuracy_after, clean_accuracy_drop = test_backdoor_attack(\n#     model, \n#     backdoor_test_loader, \n#     target_label=9, \n#     device=device, \n#     clean_test_loader=test_loader,\n#     original_clean_accuracy=clean_acc \n# )","metadata":{"execution":{"iopub.status.busy":"2024-10-01T19:19:45.446051Z","iopub.status.idle":"2024-10-01T19:19:45.446418Z","shell.execute_reply.started":"2024-10-01T19:19:45.446232Z","shell.execute_reply":"2024-10-01T19:19:45.446250Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"poisoning_rates = [0.01, 0.05]  \nfrequencies = [1000, 10000, 24000]\ntarget_label = 9\nepochs = 7\nresults = []","metadata":{"execution":{"iopub.status.busy":"2024-10-01T19:19:45.448103Z","iopub.status.idle":"2024-10-01T19:19:45.448573Z","shell.execute_reply.started":"2024-10-01T19:19:45.448319Z","shell.execute_reply":"2024-10-01T19:19:45.448343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"frequency = 10000\nfor poisoning_rate in poisoning_rates:\n    \n    print(f\"Running experiment with poisoning_rate={poisoning_rate}\")\n    \n    poisoned_train_dataset = PoisonedAudioDataset(\n        train_data, \n        target_label=target_label, \n        poisoning_rate=poisoning_rate, \n        frequency=frequency,\n        save_samples=True \n    )\n    poisoned_train_loader = DataLoader(poisoned_train_dataset, batch_size=16, shuffle=True, collate_fn=pre_dataloader)\n\n    model = CNNModel().to(device)\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n    \n    train_model(model, poisoned_train_loader, criterion, optimizer, device, epochs=epochs)\n\n    backdoor_test_dataset = PoisonedAudioDataset(\n        test_data, \n        target_label=target_label, \n        poisoning_rate=1.0, \n        frequency=frequency\n    )\n    backdoor_test_loader = DataLoader(backdoor_test_dataset, batch_size=16, shuffle=False, collate_fn=pre_dataloader)\n    \n    backdoor_success_rate, clean_accuracy_after, clean_accuracy_drop = test_backdoor_attack(\n        model, \n        backdoor_test_loader, \n        target_label=target_label, \n        device=device, \n        clean_test_loader=test_loader, \n        original_clean_accuracy=clean_acc \n    )\n    \n    results.append({\n        'poisoning_rate': poisoning_rate,\n        'backdoor_success_rate': backdoor_success_rate,\n        'clean_accuracy_after': clean_accuracy_after,\n        'clean_accuracy_drop': clean_accuracy_drop\n    })","metadata":{"execution":{"iopub.status.busy":"2024-10-01T19:19:45.450960Z","iopub.status.idle":"2024-10-01T19:19:45.451752Z","shell.execute_reply.started":"2024-10-01T19:19:45.451463Z","shell.execute_reply":"2024-10-01T19:19:45.451490Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results_df = pd.DataFrame(results)","metadata":{"execution":{"iopub.status.busy":"2024-10-01T19:19:45.452969Z","iopub.status.idle":"2024-10-01T19:19:45.453440Z","shell.execute_reply.started":"2024-10-01T19:19:45.453186Z","shell.execute_reply":"2024-10-01T19:19:45.453210Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(results_df)","metadata":{"execution":{"iopub.status.busy":"2024-10-01T19:19:45.452969Z","iopub.status.idle":"2024-10-01T19:19:45.453440Z","shell.execute_reply.started":"2024-10-01T19:19:45.453186Z","shell.execute_reply":"2024-10-01T19:19:45.453210Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results_df.to_csv('CNN-SD-BKDR-HFSoundAll.csv', sep='\\t', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-10-01T19:19:45.455108Z","iopub.status.idle":"2024-10-01T19:19:45.455579Z","shell.execute_reply.started":"2024-10-01T19:19:45.455325Z","shell.execute_reply":"2024-10-01T19:19:45.455351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}